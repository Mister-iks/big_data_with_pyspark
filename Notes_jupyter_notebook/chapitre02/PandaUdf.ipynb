{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "343d4c63-7d37-49f9-83f3-abb8d3bd855d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "from pyspark.sql.types import *\n",
    "spark=SparkSession.builder.appName('data_processing').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1d5da0",
   "metadata": {},
   "source": [
    "Par rapport aux Udf standard de Python, les udf panda sont :\n",
    "    - plus rapides\n",
    "    - plus léger en terme de temps\n",
    "    - plus léger en terme d'execution\n",
    "    La différence entre les deux réside dans le fait qu'un UDF panda s'execute en bloc par bloc\n",
    "    alors qu'un udf python s'execute ligne par ligne et par conséquent n'offre pas les avantages d'un framework distribué.\n",
    "\n",
    "On en distingue trois types qui sont:\n",
    "    ***scalar grouped map et grouped agg***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84433014-fb12-424f-801a-3359654fb212",
   "metadata": {},
   "outputs": [],
   "source": [
    "employees = spark.read.csv(\"employee.csv\", header=True, inferSchema=True) #import du fichier employee.csv\n",
    "# employees.select('salary').summary().show() à decommenter pour voir le min et le max\n",
    "min_sal =23056\n",
    "max_sal = 498069\n",
    "\n",
    "def scaled_salary(salary):\n",
    "    \"\"\"\n",
    "        Cette fonction permet de calculer l'echelonnage du salaire. \n",
    "        :param salary : le salaire dont nous devons calculer l'echelonnage\n",
    "        :return le salaire échelonné\n",
    "    \"\"\"\n",
    "    scaled_sal = (salary-min_sal)/(max_sal-min_sal)\n",
    "    return scaled_sal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f773a54a-8083-4fc7-8ed2-d85b8915d39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+--------------------+--------------------+\n",
      "|            name|salary|             company|       scaled_salary|\n",
      "+----------------+------+--------------------+--------------------+\n",
      "|Colette Guerrero|372384|            Dui Inc.|  0.7354072414860224|\n",
      "|    Preston Wall|387228|Turpis Non Enim I...|  0.7666569125476566|\n",
      "|   Cadman Bright|200634|Pellentesque A Corp.| 0.37383818969165056|\n",
      "|  Cameran Cannon| 25171|Porttitor Sceleri...|0.004452509720786589|\n",
      "| Camilla Edwards|395840|             Elit PC|  0.7847869426731479|\n",
      "|     Keiko Garza|292461|         Ornare Inc.|  0.5671528989732912|\n",
      "| Clinton Mcguire|157623|   Mauris Eu Limited| 0.28329119413573944|\n",
      "|    Maile Phelps|168556|            Urna LLC|  0.3063074063236164|\n",
      "|     Todd Oliver| 97660|       Augue Sed LLC| 0.15705675423619986|\n",
      "|Stephen Alvarado|253303|Ac Arcu Incorporated|  0.4847172603697162|\n",
      "|    Judah Farley| 85607|Mollis Nec Cursus...| 0.13168271184157065|\n",
      "| Daphne Roberson|101749|         Euismod Ltd| 0.16566493969638726|\n",
      "|   Donovan Perry|145259|           Lorem Ltd|  0.2572624328176282|\n",
      "|   Stephen Ortiz|460295| Adipiscing Enim Ltd|  0.9204779658661973|\n",
      "|   Jasper Osborn| 61448|      Nec Cursus LLP| 0.08082305115859988|\n",
      "|    Amber Rhodes|315810|Sem Elit Incorpor...|  0.6163073431674502|\n",
      "|      Allen Cook|310844|             Urna PC|  0.6058528924471541|\n",
      "|Lillith Figueroa|137931|Aliquam Gravida C...| 0.24183548660773493|\n",
      "|  Baxter Freeman|255848| Arcu Vestibulum LLP|  0.4900750084734523|\n",
      "|      Velma Todd|318071|Ornare Fusce Foun...|  0.6210672128973312|\n",
      "+----------------+------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaling_udf = pandas_udf(scaled_salary,DoubleType()) #definition de la structure de la fonction panda_udf\n",
    "employees.withColumn(\"scaled_salary\", scaling_udf(employees['salary'])).show() #ajout de la colonne scaled_salary qui contient l'echelonnage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
